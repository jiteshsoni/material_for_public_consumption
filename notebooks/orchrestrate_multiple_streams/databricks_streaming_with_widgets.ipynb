{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# 🎛️ Databricks Streaming Benchmark with Interactive Widgets\n",
        "\n",
        "This notebook uses **Databricks widgets** for interactive parameter configuration. Simply modify the widget values in the UI and run the cells.\n",
        "\n",
        "## ✨ Features:\n",
        "- **Interactive widgets** for all parameters\n",
        "- **Real-time parameter updates** \n",
        "- **Validation and error checking**\n",
        "- **Works in both Databricks and databricks-connect**\n",
        "- **Visual progress monitoring**\n",
        "\n",
        "## 📋 How to Use:\n",
        "1. **Run Cell 1** to create all parameter widgets\n",
        "2. **Modify widget values** in the Databricks UI (top of notebook)\n",
        "3. **Run remaining cells** to execute benchmark with your parameters\n",
        "4. **Re-run anytime** with different widget values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 🎛️ WIDGET CREATION - Interactive Parameter Configuration\n",
        "# ============================================================================\n",
        "\n",
        "# Import required modules\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Check if dbutils is available (Databricks environment)\n",
        "try:\n",
        "    # Create interactive widgets for all parameters\n",
        "    dbutils.widgets.text(\"streams\", \"20\", \"📊 Number of Streams\")\n",
        "    dbutils.widgets.text(\"rows_per_second\", \"500\", \"⚡ Rows per Second per Stream\")\n",
        "    dbutils.widgets.text(\"duration\", \"90\", \"🕐 Monitoring Duration (seconds)\")\n",
        "    dbutils.widgets.text(\"trigger_interval\", \"15\", \"⏱️ Trigger Interval (seconds)\")\n",
        "    dbutils.widgets.text(\"benchmark_name\", \"widget_benchmark\", \"📋 Benchmark Name\")\n",
        "    dbutils.widgets.text(\"partitions\", \"4\", \"🔧 Number of Partitions\")\n",
        "    \n",
        "    # Advanced widgets\n",
        "    dbutils.widgets.dropdown(\"output_path\", \"/Volumes/soni/default/streaming_writes/\", \n",
        "                           [\"/Volumes/soni/default/streaming_writes/\", \n",
        "                            \"/tmp/streaming_test/\"], \"📁 Output Path\")\n",
        "    \n",
        "    dbutils.widgets.dropdown(\"checkpoint_path\", \"/Volumes/soni/default/checkpoints/\", \n",
        "                           [\"/Volumes/soni/default/checkpoints/\", \n",
        "                            \"/tmp/checkpoints/\"], \"💾 Checkpoint Path\")\n",
        "    \n",
        "    # Preset configurations dropdown\n",
        "    dbutils.widgets.dropdown(\"preset_config\", \"custom\", \n",
        "                           [\"custom\", \"quick_test\", \"load_test\", \"scale_test\"], \n",
        "                           \"🎯 Preset Configuration\")\n",
        "    \n",
        "    print(\"✅ Databricks widgets created successfully!\")\n",
        "    print(\"💡 Modify the widget values at the top of this notebook\")\n",
        "    print(\"🔄 Re-run this cell after changing preset_config to update other widgets\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"⚠️ dbutils not available (running outside Databricks): {str(e)}\")\n",
        "    print(\"💡 Using default values instead\")\n",
        "    \n",
        "    # Define default values when dbutils is not available\n",
        "    class MockWidgets:\n",
        "        def get(self, key):\n",
        "            defaults = {\n",
        "                \"streams\": \"20\",\n",
        "                \"rows_per_second\": \"500\", \n",
        "                \"duration\": \"90\",\n",
        "                \"trigger_interval\": \"15\",\n",
        "                \"benchmark_name\": \"widget_benchmark\",\n",
        "                \"partitions\": \"4\",\n",
        "                \"output_path\": \"/Volumes/soni/default/streaming_writes/\",\n",
        "                \"checkpoint_path\": \"/Volumes/soni/default/checkpoints/\",\n",
        "                \"preset_config\": \"custom\"\n",
        "            }\n",
        "            return defaults.get(key, \"\")\n",
        "    \n",
        "    # Create mock dbutils for compatibility\n",
        "    class MockDbutils:\n",
        "        def __init__(self):\n",
        "            self.widgets = MockWidgets()\n",
        "    \n",
        "    dbutils = MockDbutils()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 📊 PARAMETER READING & PRESET CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "def apply_preset_config(preset):\n",
        "    \"\"\"Apply preset configurations based on selection\"\"\"\n",
        "    presets = {\n",
        "        \"quick_test\": {\n",
        "            \"streams\": \"10\",\n",
        "            \"rows_per_second\": \"100\", \n",
        "            \"duration\": \"60\",\n",
        "            \"trigger_interval\": \"15\",\n",
        "            \"benchmark_name\": \"quick_test\",\n",
        "            \"partitions\": \"4\"\n",
        "        },\n",
        "        \"load_test\": {\n",
        "            \"streams\": \"50\",\n",
        "            \"rows_per_second\": \"1000\",\n",
        "            \"duration\": \"300\", \n",
        "            \"trigger_interval\": \"10\",\n",
        "            \"benchmark_name\": \"load_test\",\n",
        "            \"partitions\": \"8\"\n",
        "        },\n",
        "        \"scale_test\": {\n",
        "            \"streams\": \"100\",\n",
        "            \"rows_per_second\": \"500\",\n",
        "            \"duration\": \"300\",\n",
        "            \"trigger_interval\": \"15\", \n",
        "            \"benchmark_name\": \"scale_test\",\n",
        "            \"partitions\": \"8\"\n",
        "        }\n",
        "    }\n",
        "    return presets.get(preset, {})\n",
        "\n",
        "# Read widget values\n",
        "preset_config = dbutils.widgets.get(\"preset_config\")\n",
        "print(f\"🎯 Selected preset: {preset_config}\")\n",
        "\n",
        "# Apply preset if selected\n",
        "if preset_config != \"custom\":\n",
        "    preset_values = apply_preset_config(preset_config)\n",
        "    print(f\"📋 Applying {preset_config} preset configuration:\")\n",
        "    for key, value in preset_values.items():\n",
        "        print(f\"   {key}: {value}\")\n",
        "else:\n",
        "    preset_values = {}\n",
        "    print(\"🔧 Using custom widget values\")\n",
        "\n",
        "# Read final configuration from widgets (with preset override)\n",
        "config = {\n",
        "    \"streams\": int(preset_values.get(\"streams\", dbutils.widgets.get(\"streams\"))),\n",
        "    \"rows_per_second\": int(preset_values.get(\"rows_per_second\", dbutils.widgets.get(\"rows_per_second\"))),\n",
        "    \"duration\": int(preset_values.get(\"duration\", dbutils.widgets.get(\"duration\"))),\n",
        "    \"trigger_interval\": int(preset_values.get(\"trigger_interval\", dbutils.widgets.get(\"trigger_interval\"))),\n",
        "    \"benchmark_name\": preset_values.get(\"benchmark_name\", dbutils.widgets.get(\"benchmark_name\")),\n",
        "    \"partitions\": int(preset_values.get(\"partitions\", dbutils.widgets.get(\"partitions\"))),\n",
        "    \"output_path\": dbutils.widgets.get(\"output_path\"),\n",
        "    \"checkpoint_path\": dbutils.widgets.get(\"checkpoint_path\")\n",
        "}\n",
        "\n",
        "# Validate parameters\n",
        "def validate_config(config):\n",
        "    \"\"\"Validate configuration parameters\"\"\"\n",
        "    issues = []\n",
        "    \n",
        "    if config[\"streams\"] <= 0 or config[\"streams\"] > 1000:\n",
        "        issues.append(\"⚠️ streams should be between 1 and 1000\")\n",
        "    \n",
        "    if config[\"rows_per_second\"] <= 0 or config[\"rows_per_second\"] > 10000:\n",
        "        issues.append(\"⚠️ rows_per_second should be between 1 and 10000\")\n",
        "        \n",
        "    if config[\"duration\"] < 0:\n",
        "        issues.append(\"⚠️ duration should be >= 0 (0 = no monitoring)\")\n",
        "        \n",
        "    if config[\"trigger_interval\"] <= 0 or config[\"trigger_interval\"] > 300:\n",
        "        issues.append(\"⚠️ trigger_interval should be between 1 and 300 seconds\")\n",
        "    \n",
        "    total_throughput = config[\"streams\"] * config[\"rows_per_second\"]\n",
        "    if total_throughput > 100000:\n",
        "        issues.append(f\"⚠️ Total throughput ({total_throughput:,} rows/sec) is very high - ensure cluster can handle it\")\n",
        "    \n",
        "    return issues\n",
        "\n",
        "# Validate and display configuration\n",
        "validation_issues = validate_config(config)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"🚀 FINAL CONFIGURATION FROM WIDGETS\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"📊 Benchmark Name: {config['benchmark_name']}\")\n",
        "print(f\"📈 Number of Streams: {config['streams']}\")\n",
        "print(f\"⚡ Rows per Second per Stream: {config['rows_per_second']}\")\n",
        "print(f\"📊 Total Throughput: {config['streams'] * config['rows_per_second']:,} rows/second\")\n",
        "print(f\"⏱️  Trigger Interval: {config['trigger_interval']} seconds\")\n",
        "print(f\"🕐 Monitoring Duration: {config['duration']} seconds\")\n",
        "print(f\"🔧 Partitions: {config['partitions']}\")\n",
        "print(f\"📁 Output Path: {config['output_path']}\")\n",
        "print(f\"💾 Checkpoint Path: {config['checkpoint_path']}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Display validation results\n",
        "if validation_issues:\n",
        "    print(\"\\n🚨 CONFIGURATION WARNINGS:\")\n",
        "    for issue in validation_issues:\n",
        "        print(f\"   {issue}\")\n",
        "    print(\"\\n💡 Please review your widget values and re-run this cell\")\n",
        "else:\n",
        "    print(\"\\n✅ Configuration validation passed!\")\n",
        "\n",
        "print(f\"\\n🕐 Configuration read at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"💡 Modify widgets above and re-run this cell to update configuration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 📦 DEPENDENCIES & SPARK CONNECTION\n",
        "# ============================================================================\n",
        "\n",
        "import subprocess\n",
        "import sys\n",
        "import time\n",
        "import configparser\n",
        "\n",
        "# Install dbldatagen if needed\n",
        "try:\n",
        "    import dbldatagen as dg\n",
        "    print(\"✅ dbldatagen is available\")\n",
        "except ImportError:\n",
        "    print(\"📦 Installing dbldatagen...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"dbldatagen\"])\n",
        "    import dbldatagen as dg\n",
        "    print(\"✅ dbldatagen installed successfully\")\n",
        "\n",
        "# Import Spark components\n",
        "try:\n",
        "    # Try Databricks Connect first\n",
        "    from databricks.connect import DatabricksSession\n",
        "    spark = DatabricksSession.builder.getOrCreate()\n",
        "    connection_type = \"Databricks Connect\"\n",
        "    print(\"✅ Connected via Databricks Connect\")\n",
        "except:\n",
        "    # Fallback to regular Spark session (for local environments)\n",
        "    from pyspark.sql import SparkSession\n",
        "    spark = SparkSession.builder.appName(\"WidgetStreamingBenchmark\").getOrCreate()\n",
        "    connection_type = \"Regular Spark Session\"\n",
        "    print(\"✅ Connected via regular Spark session\")\n",
        "\n",
        "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, DoubleType, IntegerType\n",
        "from pyspark.sql.functions import expr\n",
        "\n",
        "print(f\"🔗 Spark Version: {spark.version}\")\n",
        "print(f\"🔌 Connection Type: {connection_type}\")\n",
        "\n",
        "# Get cluster information\n",
        "def get_cluster_info():\n",
        "    \"\"\"Get cluster configuration from Databricks config\"\"\"\n",
        "    try:\n",
        "        config_path = os.path.expanduser('~/.databrickscfg')\n",
        "        if os.path.exists(config_path):\n",
        "            cfg = configparser.ConfigParser()\n",
        "            cfg.read(config_path)\n",
        "            \n",
        "            for profile in ['DEFAULT', 'DEFAULT2']:\n",
        "                if profile in cfg:\n",
        "                    cluster_id = cfg[profile].get('cluster_id', '').strip('%')\n",
        "                    host = cfg[profile].get('host', 'Unknown')\n",
        "                    if cluster_id:\n",
        "                        return {\n",
        "                            'cluster_id': cluster_id,\n",
        "                            'host': host, \n",
        "                            'profile': profile,\n",
        "                            'found': True\n",
        "                        }\n",
        "        return {'found': False}\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Could not read cluster info: {str(e)}\")\n",
        "        return {'found': False}\n",
        "\n",
        "cluster_info = get_cluster_info()\n",
        "\n",
        "print(\"\\n🖥️ Cluster Information:\")\n",
        "print(\"-\" * 40)\n",
        "if cluster_info['found']:\n",
        "    print(f\"📍 Host: {cluster_info['host']}\")\n",
        "    print(f\"🔗 Cluster ID: {cluster_info['cluster_id']}\")\n",
        "    print(f\"⚙️ Profile: {cluster_info['profile']}\")\n",
        "else:\n",
        "    print(\"⚠️ Cluster information not found in config\")\n",
        "    print(\"💡 Running in local/generic mode\")\n",
        "\n",
        "print(f\"✅ Connection Status: {'Remote Databricks' if cluster_info.get('host', '').find('databricks') != -1 else 'Local/Generic'}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "print(f\"\\n🕐 Dependencies loaded at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"✅ Ready to proceed with benchmark execution!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 🔧 DATA GENERATOR SETUP WITH WIDGET CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Define IoT sensor data schema\n",
        "iot_schema = StructType([\n",
        "    StructField(\"device_id\", StringType(), False),\n",
        "    StructField(\"event_timestamp\", TimestampType(), False),\n",
        "    StructField(\"temperature\", DoubleType(), False),\n",
        "    StructField(\"humidity\", DoubleType(), False),\n",
        "    StructField(\"pressure\", DoubleType(), False),\n",
        "    StructField(\"battery_level\", IntegerType(), False),\n",
        "    StructField(\"device_type\", StringType(), False),\n",
        "    StructField(\"error_code\", IntegerType(), True),\n",
        "    StructField(\"signal_strength\", IntegerType(), False)\n",
        "])\n",
        "\n",
        "print(\"📋 IoT Sensor Data Schema:\")\n",
        "print(\"=\" * 50)\n",
        "for i, field in enumerate(iot_schema.fields, 1):\n",
        "    nullable_str = \"nullable\" if field.nullable else \"required\"\n",
        "    print(f\"{i:2d}. {field.name:<18} | {field.dataType.simpleString():<12} | {nullable_str}\")\n",
        "\n",
        "print(f\"\\n🔧 Creating data generator with widget configuration...\")\n",
        "print(f\"   Using {config['partitions']} partitions\")\n",
        "print(f\"   Generating {config['rows_per_second']} rows per second per stream\")\n",
        "\n",
        "try:\n",
        "    # Create the data generator with widget-configured parameters\n",
        "    dataspec = (\n",
        "        dg.DataGenerator(spark, name=\"iot_widget_data\", partitions=config['partitions'])\n",
        "        .withSchema(iot_schema)\n",
        "        .withColumnSpec(\"device_id\", percentNulls=0.1, minValue=1000, maxValue=9999, prefix=\"DEV_\", random=True)\n",
        "        .withColumnSpec(\"event_timestamp\", begin=\"2023-01-01 00:00:00\", end=\"2023-12-31 23:59:59\", random=True)\n",
        "        .withColumnSpec(\"temperature\", minValue=-10.0, maxValue=40.0, random=True)\n",
        "        .withColumnSpec(\"humidity\", minValue=0.0, maxValue=100.0, random=True)\n",
        "        .withColumnSpec(\"pressure\", minValue=900.0, maxValue=1100.0, random=True)\n",
        "        .withColumnSpec(\"battery_level\", minValue=0, maxValue=100, random=True)\n",
        "        .withColumnSpec(\"device_type\", values=[\"Sensor\", \"Actuator\", \"Gateway\", \"Controller\"], random=True)\n",
        "        .withColumnSpec(\"error_code\", minValue=0, maxValue=999, random=True, percentNulls=0.2)\n",
        "        .withColumnSpec(\"signal_strength\", minValue=-100, maxValue=0, random=True)\n",
        "    )\n",
        "    print(\"✅ Data generator specification created successfully\")\n",
        "    \n",
        "    # Build the streaming DataFrame with widget-configured row rate\n",
        "    streaming_df = dataspec.build(\n",
        "        withStreaming=True,\n",
        "        options={'rowsPerSecond': config['rows_per_second']}\n",
        "    )\n",
        "    print(f\"✅ Streaming DataFrame created ({config['rows_per_second']} rows/second per stream)\")\n",
        "    \n",
        "    # Display schema preview\n",
        "    print(f\"\\n📄 Generated DataFrame Schema:\")\n",
        "    streaming_df.printSchema()\n",
        "    \n",
        "    # Configuration summary\n",
        "    print(f\"\\n📊 Data Generation Summary:\")\n",
        "    print(f\"   🎯 Target per stream: {config['rows_per_second']} rows/second\")\n",
        "    print(f\"   📈 Number of streams: {config['streams']}\")\n",
        "    print(f\"   📊 Total target throughput: {config['streams'] * config['rows_per_second']:,} rows/second\")\n",
        "    print(f\"   🔧 Data partitions: {config['partitions']}\")\n",
        "    print(f\"   ⏱️ Processing interval: {config['trigger_interval']} seconds\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"❌ Failed to create data generator: {str(e)}\")\n",
        "    print(f\"💡 Check your widget configuration and Spark connection\")\n",
        "    raise e\n",
        "\n",
        "# Estimate resource requirements\n",
        "total_throughput = config['streams'] * config['rows_per_second']\n",
        "estimated_cpu_cores = max(4, config['streams'] // 5)  # Rough estimate\n",
        "estimated_memory_gb = max(8, config['streams'] // 2)  # Rough estimate\n",
        "\n",
        "print(f\"\\n💻 Estimated Resource Requirements:\")\n",
        "print(f\"   📊 Total Throughput: {total_throughput:,} rows/second\")\n",
        "print(f\"   🖥️ Recommended CPU Cores: {estimated_cpu_cores}+\")\n",
        "print(f\"   💾 Recommended Memory: {estimated_memory_gb}+ GB\")\n",
        "print(f\"   ⚠️ Ensure your cluster has sufficient resources!\")\n",
        "\n",
        "print(f\"\\n✅ Data generator setup complete!\")\n",
        "print(f\"🔄 Ready to start streaming with widget configuration\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 🚀 STREAM CREATION & STARTUP WITH WIDGET CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"🚀 Starting {config['streams']} concurrent streaming queries...\")\n",
        "print(f\"📊 Using configuration from widgets:\")\n",
        "print(f\"   Benchmark: {config['benchmark_name']}\")\n",
        "print(f\"   Target throughput: {config['streams'] * config['rows_per_second']:,} rows/second\")\n",
        "print(f\"   Processing interval: {config['trigger_interval']} seconds\")\n",
        "print(f\"   Output: {config['output_path']}\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Initialize tracking variables\n",
        "streaming_queries = []\n",
        "successful_starts = 0\n",
        "start_time = time.time()\n",
        "\n",
        "# Create and start each stream using widget configuration\n",
        "for i in range(config['streams']):\n",
        "    stream_name = f\"{config['benchmark_name']}_widget_stream_{i+1:03d}\"\n",
        "    output_path = f\"{config['output_path']}{config['benchmark_name']}_widget_stream_{i+1:03d}/\"\n",
        "    checkpoint_path = f\"{config['checkpoint_path']}checkpoint_{config['benchmark_name']}_widget_{stream_name}/\"\n",
        "    \n",
        "    try:\n",
        "        # Create the streaming query with widget-configured parameters\n",
        "        query = (\n",
        "            streaming_df\n",
        "            .writeStream\n",
        "            .format(\"delta\")\n",
        "            .outputMode(\"append\")\n",
        "            .option(\"checkpointLocation\", checkpoint_path)\n",
        "            .trigger(processingTime=f'{config[\"trigger_interval\"]} seconds')\n",
        "            .queryName(stream_name)\n",
        "            .start(output_path)\n",
        "        )\n",
        "        \n",
        "        streaming_queries.append(query)\n",
        "        successful_starts += 1\n",
        "        \n",
        "        # Show progress indicators\n",
        "        if successful_starts % 10 == 0 or successful_starts <= 5 or i == config['streams'] - 1:\n",
        "            print(f\"✅ Started {successful_starts:3d}/{config['streams']}: {stream_name}\")\n",
        "        elif successful_starts % 5 == 0:\n",
        "            print(f\"📈 Progress: {successful_starts}/{config['streams']} streams started...\")\n",
        "        \n",
        "        # Small delay to prevent overwhelming the cluster\n",
        "        time.sleep(0.2)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Failed to start stream {stream_name}: {str(e)}\")\n",
        "        \n",
        "        # Show helpful error messages\n",
        "        if \"No space left on device\" in str(e):\n",
        "            print(\"💡 Cluster is running out of disk space - consider restarting cluster\")\n",
        "        elif \"connection\" in str(e).lower():\n",
        "            print(\"💡 Connection issue - check cluster status in Databricks UI\")\n",
        "        else:\n",
        "            print(\"💡 Check cluster resources and configuration\")\n",
        "            \n",
        "        print(\"⏹️ Stopping further stream creation due to error\")\n",
        "        break\n",
        "\n",
        "# Calculate startup time and show results\n",
        "startup_time = time.time() - start_time\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(f\"🎉 Stream Startup Complete!\")\n",
        "print(f\"✅ Successfully started: {successful_starts}/{config['streams']} streams\")\n",
        "print(f\"⏱️ Startup time: {startup_time:.1f} seconds\")\n",
        "print(f\"📈 Target throughput: {successful_starts * config['rows_per_second']:,} rows/second\")\n",
        "\n",
        "if successful_starts == 0:\n",
        "    print(\"\\n❌ No streams were started successfully!\")\n",
        "    print(\"💡 Check your cluster status and widget configuration\")\n",
        "    print(\"🔄 Try reducing the number of streams or restarting your cluster\")\n",
        "else:\n",
        "    print(f\"\\n💡 {successful_starts} streams are now running on your Databricks cluster!\")\n",
        "    print(f\"🔗 Monitor them in Databricks UI: Compute → Cluster → Spark UI → Streaming\")\n",
        "    \n",
        "    # Validate stream status immediately\n",
        "    print(f\"\\n📊 Immediate Stream Status Check:\")\n",
        "    active_count = 0\n",
        "    for i, query in enumerate(streaming_queries[:5]):  # Check first 5\n",
        "        try:\n",
        "            status = \"🟢 Active\" if query.isActive else \"🔴 Inactive\"\n",
        "            print(f\"   {query.name}: {status}\")\n",
        "            if query.isActive:\n",
        "                active_count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"   {query.name}: ❌ Error checking status\")\n",
        "    \n",
        "    if len(streaming_queries) > 5:\n",
        "        remaining_active = sum(1 for q in streaming_queries[5:] if q.isActive)\n",
        "        active_count += remaining_active\n",
        "        print(f\"   ... and {len(streaming_queries) - 5} more streams\")\n",
        "    \n",
        "    print(f\"\\n📈 Summary: {active_count}/{successful_starts} streams are active\")\n",
        "    success_rate = (active_count / successful_starts) * 100 if successful_starts > 0 else 0\n",
        "    print(f\"🎯 Immediate success rate: {success_rate:.1f}%\")\n",
        "\n",
        "# Store results for next cells\n",
        "benchmark_start_time = time.time()\n",
        "initial_active_count = active_count if 'active_count' in locals() else 0\n",
        "\n",
        "print(f\"\\n🕐 Startup completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"🔄 Ready for monitoring phase!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ⏳ REAL-TIME MONITORING WITH WIDGET CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "if 'streaming_queries' not in locals() or not streaming_queries:\n",
        "    print(\"⚠️ No streaming queries found - please run the previous cell first\")\n",
        "elif config['duration'] <= 0:\n",
        "    print(\"ℹ️ Monitoring duration set to 0 - skipping monitoring phase\")\n",
        "    print(\"💡 Streams will continue running in the background\")\n",
        "else:\n",
        "    print(f\"⏳ Monitoring {len(streaming_queries)} streams for {config['duration']} seconds...\")\n",
        "    print(f\"🔄 Progress updates every 15 seconds\")\n",
        "    print(f\"📊 Using widget configuration: {config['benchmark_name']}\")\n",
        "    print(\"=\" * 100)\n",
        "    \n",
        "    monitor_start = time.time()\n",
        "    check_interval = 15  # seconds between progress checks\n",
        "    next_check = monitor_start + check_interval\n",
        "    \n",
        "    # Monitoring loop\n",
        "    while time.time() - monitor_start < config['duration']:\n",
        "        current_time = time.time()\n",
        "        \n",
        "        if current_time >= next_check:\n",
        "            elapsed = current_time - monitor_start\n",
        "            remaining = config['duration'] - elapsed\n",
        "            \n",
        "            print(f\"\\n📊 Progress Check - {elapsed:.0f}s elapsed, {remaining:.0f}s remaining\")\n",
        "            print(\"-\" * 90)\n",
        "            \n",
        "            # Check stream health and gather metrics\n",
        "            current_active = 0\n",
        "            total_input_rate = 0\n",
        "            total_processed_rate = 0\n",
        "            sample_streams_shown = 0\n",
        "            batch_info = []\n",
        "            \n",
        "            for i, query in enumerate(streaming_queries):\n",
        "                try:\n",
        "                    if query.isActive:\n",
        "                        current_active += 1\n",
        "                        \n",
        "                        # Get progress information\n",
        "                        progress = query.lastProgress\n",
        "                        if progress:\n",
        "                            batch_id = progress.get('batchId', 'N/A')\n",
        "                            input_rate = progress.get('inputRowsPerSecond', 0)\n",
        "                            processed_rate = progress.get('processedRowsPerSecond', 0)\n",
        "                            \n",
        "                            total_input_rate += input_rate\n",
        "                            total_processed_rate += processed_rate\n",
        "                            batch_info.append((query.name, batch_id, input_rate, processed_rate))\n",
        "                            \n",
        "                            # Show detailed progress for first 5 streams\n",
        "                            if sample_streams_shown < 5:\n",
        "                                print(f\"  {query.name}: Batch {batch_id}, Input: {input_rate:.0f}/sec, Processed: {processed_rate:.0f}/sec\")\n",
        "                                sample_streams_shown += 1\n",
        "                        else:\n",
        "                            if sample_streams_shown < 5:\n",
        "                                print(f\"  {query.name}: Starting up...\")\n",
        "                                sample_streams_shown += 1\n",
        "                            \n",
        "                except Exception as e:\n",
        "                    if sample_streams_shown < 5:\n",
        "                        print(f\"  {query.name}: Error - {str(e)[:30]}\")\n",
        "                        sample_streams_shown += 1\n",
        "            \n",
        "            if len(streaming_queries) > 5:\n",
        "                print(f\"  ... and {len(streaming_queries) - 5} more streams\")\n",
        "            \n",
        "            # Summary statistics\n",
        "            print(f\"\\n  📈 Summary at {elapsed:.0f}s:\")\n",
        "            print(f\"    🟢 Active Streams: {current_active}/{len(streaming_queries)}\")\n",
        "            print(f\"    📊 Expected Rate (from widgets): {current_active * config['rows_per_second']:,} rows/second\")\n",
        "            print(f\"    📈 Actual Input Rate: {total_input_rate:.0f} rows/second\")\n",
        "            print(f\"    ⚡ Processing Rate: {total_processed_rate:.0f} rows/second\")\n",
        "            \n",
        "            # Performance metrics\n",
        "            if current_active > 0:\n",
        "                avg_input_per_stream = total_input_rate / current_active\n",
        "                avg_processed_per_stream = total_processed_rate / current_active\n",
        "                expected_per_stream = config['rows_per_second']\n",
        "                \n",
        "                input_efficiency = (avg_input_per_stream / expected_per_stream * 100) if expected_per_stream > 0 else 0\n",
        "                processing_efficiency = (avg_processed_per_stream / avg_input_per_stream * 100) if avg_input_per_stream > 0 else 0\n",
        "                \n",
        "                print(f\"    📏 Avg Input/Stream: {avg_input_per_stream:.0f} rows/sec ({input_efficiency:.1f}% of target)\")\n",
        "                print(f\"    ⚙️ Processing Efficiency: {processing_efficiency:.1f}%\")\n",
        "            \n",
        "            # Health indicator\n",
        "            health_score = (current_active / len(streaming_queries)) * 100\n",
        "            health_emoji = \"🟢\" if health_score >= 90 else \"🟡\" if health_score >= 70 else \"🔴\"\n",
        "            print(f\"    {health_emoji} Health Score: {health_score:.1f}%\")\n",
        "            \n",
        "            # Widget configuration reminder\n",
        "            if elapsed > 30:  # After 30 seconds, show widget info\n",
        "                print(f\"    🎛️ Widget Config: {config['benchmark_name']} ({config['streams']} streams @ {config['rows_per_second']}/sec)\")\n",
        "            \n",
        "            next_check += check_interval\n",
        "        \n",
        "        # Short sleep to prevent busy waiting\n",
        "        time.sleep(1)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 100)\n",
        "    print(\"✅ Monitoring period completed!\")\n",
        "    \n",
        "    # Final status check\n",
        "    final_active = sum(1 for q in streaming_queries if q.isActive)\n",
        "    print(f\"\\n📊 Final Status:\")\n",
        "    print(f\"   🟢 Active Streams: {final_active}/{len(streaming_queries)}\")\n",
        "    print(f\"   📈 Final Throughput: {final_active * config['rows_per_second']:,} rows/second\")\n",
        "    print(f\"   🕐 Total Runtime: {(time.time() - benchmark_start_time):.1f} seconds\")\n",
        "    \n",
        "    if final_active > 0:\n",
        "        print(f\"\\n💡 Next Steps:\")\n",
        "        print(f\"   - {final_active} streams are still running on your cluster\")\n",
        "        print(f\"   - Data location: {config['output_path']}{config['benchmark_name']}_widget_stream_*/\")\n",
        "        print(f\"   - Use the utility functions in the next cell to manage streams\")\n",
        "\n",
        "print(f\"\\n🕐 Monitoring completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"🔄 Ready for final results and stream management!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 📊 FINAL RESULTS & STREAM MANAGEMENT UTILITIES\n",
        "# ============================================================================\n",
        "\n",
        "# Final benchmark results based on widget configuration\n",
        "if 'streaming_queries' in locals() and streaming_queries:\n",
        "    final_active = sum(1 for q in streaming_queries if q.isActive)\n",
        "    total_started = len(streaming_queries)\n",
        "    success_rate = (final_active / total_started) * 100 if total_started > 0 else 0\n",
        "    actual_throughput = final_active * config['rows_per_second']\n",
        "    target_throughput = config['streams'] * config['rows_per_second']\n",
        "    \n",
        "    print(\"=\" * 100)\n",
        "    print(\"🏆 DATABRICKS STREAMING BENCHMARK - FINAL RESULTS\")\n",
        "    print(\"=\" * 100)\n",
        "    \n",
        "    print(f\"\\n📋 Widget Configuration Used:\")\n",
        "    print(f\"   🎯 Benchmark Name: {config['benchmark_name']}\")\n",
        "    print(f\"   📊 Target Streams: {config['streams']}\")\n",
        "    print(f\"   ⚡ Rows per Second per Stream: {config['rows_per_second']}\")\n",
        "    print(f\"   ⏱️ Trigger Interval: {config['trigger_interval']} seconds\")\n",
        "    print(f\"   🕐 Monitoring Duration: {config['duration']} seconds\")\n",
        "    print(f\"   🔧 Partitions: {config['partitions']}\")\n",
        "    \n",
        "    print(f\"\\n📈 Performance Results:\")\n",
        "    print(f\"   ✅ Successfully Started: {total_started}/{config['streams']} streams\")\n",
        "    print(f\"   🟢 Currently Active: {final_active}/{total_started} streams\")\n",
        "    print(f\"   🎯 Success Rate: {success_rate:.1f}%\")\n",
        "    print(f\"   📊 Target Throughput: {target_throughput:,} rows/second\")\n",
        "    print(f\"   📈 Actual Throughput: {actual_throughput:,} rows/second\")\n",
        "    print(f\"   📏 Throughput Achievement: {(actual_throughput/target_throughput*100):.1f}%\")\n",
        "    \n",
        "    # Performance rating based on widget targets\n",
        "    if success_rate >= 95 and actual_throughput >= target_throughput * 0.9:\n",
        "        rating = \"🌟 EXCELLENT\"\n",
        "        rating_color = \"🟢\"\n",
        "    elif success_rate >= 80 and actual_throughput >= target_throughput * 0.7:\n",
        "        rating = \"👍 GOOD\"\n",
        "        rating_color = \"🟡\"\n",
        "    elif success_rate >= 60:\n",
        "        rating = \"⚠️ FAIR\"\n",
        "        rating_color = \"🟡\"\n",
        "    else:\n",
        "        rating = \"❌ NEEDS IMPROVEMENT\"\n",
        "        rating_color = \"🔴\"\n",
        "    \n",
        "    print(f\"\\n{rating_color} Overall Rating: {rating}\")\n",
        "    \n",
        "    print(f\"\\n📁 Data Location:\")\n",
        "    print(f\"   {config['output_path']}{config['benchmark_name']}_widget_stream_*/\")\n",
        "    print(f\"\\n💾 Checkpoint Location:\")\n",
        "    print(f\"   {config['checkpoint_path']}checkpoint_{config['benchmark_name']}_widget_*/\")\n",
        "    \n",
        "    print(f\"\\n🕐 Benchmark Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    \n",
        "else:\n",
        "    print(\"⚠️ No streaming queries found - please run the previous cells first\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 100)\n",
        "\n",
        "# Utility functions for stream management\n",
        "print(\"🛠️ STREAM MANAGEMENT UTILITIES\")\n",
        "print(\"=\" * 100)\n",
        "\n",
        "def stop_all_widget_streams():\n",
        "    \"\"\"Stop all streams from this widget-based benchmark\"\"\"\n",
        "    if 'streaming_queries' not in locals() or not streaming_queries:\n",
        "        print(\"⚠️ No streaming queries found\")\n",
        "        return\n",
        "    \n",
        "    print(f\"⏹️ Stopping {len(streaming_queries)} widget streams...\")\n",
        "    stopped_count = 0\n",
        "    \n",
        "    for query in streaming_queries:\n",
        "        try:\n",
        "            if query.isActive:\n",
        "                query.stop()\n",
        "                stopped_count += 1\n",
        "                print(f\"✅ Stopped: {query.name}\")\n",
        "            else:\n",
        "                print(f\"ℹ️ Already stopped: {query.name}\")\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error stopping {query.name}: {str(e)}\")\n",
        "    \n",
        "    print(f\"\\n🎉 Successfully stopped {stopped_count} streams\")\n",
        "    return stopped_count\n",
        "\n",
        "def check_widget_stream_status():\n",
        "    \"\"\"Check the current status of all widget streams\"\"\"\n",
        "    if 'streaming_queries' not in locals() or not streaming_queries:\n",
        "        print(\"⚠️ No streaming queries found\")\n",
        "        return\n",
        "    \n",
        "    print(f\"📊 Checking status of {len(streaming_queries)} widget streams...\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    active_count = 0\n",
        "    for i, query in enumerate(streaming_queries):\n",
        "        try:\n",
        "            status = \"🟢 Active\" if query.isActive else \"🔴 Stopped\"\n",
        "            if query.isActive:\n",
        "                active_count += 1\n",
        "                # Try to get progress info\n",
        "                progress = query.lastProgress\n",
        "                if progress:\n",
        "                    batch_id = progress.get('batchId', 'N/A')\n",
        "                    input_rate = progress.get('inputRowsPerSecond', 0)\n",
        "                    print(f\"{i+1:3d}. {query.name}: {status} (Batch: {batch_id}, Rate: {input_rate:.0f}/sec)\")\n",
        "                else:\n",
        "                    print(f\"{i+1:3d}. {query.name}: {status} (Starting up...)\")\n",
        "            else:\n",
        "                print(f\"{i+1:3d}. {query.name}: {status}\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            print(f\"{i+1:3d}. {query.name}: ❌ Error checking status\")\n",
        "    \n",
        "    print(\"-\" * 80)\n",
        "    print(f\"📈 Summary: {active_count}/{len(streaming_queries)} streams are active\")\n",
        "    print(f\"🎯 Widget Config: {config['benchmark_name']} ({config['streams']} streams @ {config['rows_per_second']}/sec)\")\n",
        "    return active_count\n",
        "\n",
        "def show_widget_stream_progress():\n",
        "    \"\"\"Show detailed progress information for active widget streams\"\"\"\n",
        "    if 'streaming_queries' not in locals() or not streaming_queries:\n",
        "        print(\"⚠️ No streaming queries found\")\n",
        "        return\n",
        "    \n",
        "    print(f\"📈 Progress report for widget benchmark: {config['benchmark_name']}\")\n",
        "    print(\"=\" * 90)\n",
        "    \n",
        "    total_input_rate = 0\n",
        "    total_processed_rate = 0\n",
        "    active_streams = 0\n",
        "    \n",
        "    for query in streaming_queries:\n",
        "        try:\n",
        "            if query.isActive:\n",
        "                active_streams += 1\n",
        "                progress = query.lastProgress\n",
        "                if progress:\n",
        "                    batch_id = progress.get('batchId', 'N/A')\n",
        "                    input_rate = progress.get('inputRowsPerSecond', 0)\n",
        "                    processed_rate = progress.get('processedRowsPerSecond', 0)\n",
        "                    batch_duration = progress.get('batchDuration', 0)\n",
        "                    \n",
        "                    total_input_rate += input_rate\n",
        "                    total_processed_rate += processed_rate\n",
        "                    \n",
        "                    print(f\"{query.name}:\")\n",
        "                    print(f\"  Batch: {batch_id} | Input: {input_rate:.0f}/sec | Processed: {processed_rate:.0f}/sec | Duration: {batch_duration}ms\")\n",
        "        except Exception as e:\n",
        "            print(f\"{query.name}: Error getting progress\")\n",
        "    \n",
        "    print(\"=\" * 90)\n",
        "    print(f\"📊 Overall Totals:\")\n",
        "    print(f\"   Active Streams: {active_streams}/{len(streaming_queries)}\")\n",
        "    print(f\"   Expected Rate (from widgets): {active_streams * config['rows_per_second']:,} rows/second\")\n",
        "    print(f\"   Actual Input Rate: {total_input_rate:.0f} rows/second\")\n",
        "    print(f\"   Processing Rate: {total_processed_rate:.0f} rows/second\")\n",
        "    \n",
        "    return {\"active\": active_streams, \"input_rate\": total_input_rate, \"processed_rate\": total_processed_rate}\n",
        "\n",
        "# Instructions for using utility functions\n",
        "print(f\"\\n💡 Available Functions (based on your widget configuration):\")\n",
        "print(f\"   📊 check_widget_stream_status() - Check all stream statuses\")\n",
        "print(f\"   📈 show_widget_stream_progress() - Show detailed progress\")\n",
        "print(f\"   ⏹️ stop_all_widget_streams() - Stop all streams\")\n",
        "\n",
        "print(f\"\\n🎛️ Widget Configuration Summary:\")\n",
        "print(f\"   Benchmark: {config.get('benchmark_name', 'N/A')}\")\n",
        "print(f\"   Streams: {config.get('streams', 'N/A')}\")\n",
        "print(f\"   Rate: {config.get('rows_per_second', 'N/A')} rows/sec per stream\")\n",
        "print(f\"   Duration: {config.get('duration', 'N/A')} seconds\")\n",
        "\n",
        "if 'streaming_queries' in locals() and streaming_queries and final_active > 0:\n",
        "    print(f\"\\n🔗 Your {final_active} active streams are running on the Databricks cluster!\")\n",
        "    print(f\"💡 Use the utility functions above to monitor or stop them\")\n",
        "    print(f\"🎯 Total throughput: {final_active * config['rows_per_second']:,} rows/second\")\n",
        "\n",
        "print(\"\\n🎉 Widget-based benchmark complete! Modify widgets and re-run cells for different configurations.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
