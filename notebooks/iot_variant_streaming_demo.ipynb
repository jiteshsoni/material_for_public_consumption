{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c50d2de-f985-4c2e-9103-9c1622b9268f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": "# IoT Sensor Data Demo with VARIANT Type\n\nThis notebook demonstrates IoT sensor data streaming with VARIANT columns in Databricks:\n\n## Features\n- **VARIANT Column Support**: Store complex nested JSON metadata\n- **Realistic Data Generation**: Uses dbldatagen for realistic IoT sensor data\n- **Streaming Processing**: Real-time data ingestion and processing\n- **Simple Implementation**: Clean, focused code demonstrating core functionality\n- **Databricks Cluster Optimized**: Designed for remote cluster execution\n\n## Prerequisites\n- Databricks Runtime 13.3 LTS or higher\n- Unity Catalog enabled workspace with volume access\n- Cluster with appropriate permissions for streaming and Delta operations\n- dbldatagen library for realistic data generation\n\n## Architecture\n- dbldatagen ‚Üí Streaming source ‚Üí Delta table with VARIANT columns ‚Üí Real-time analytics\n- Realistic IoT sensor data with weighted distributions and proper data types"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b30d5bc-e90d-45d9-bb35-858235e96233",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# Install packages and restart Python runtime\n%pip install dbldatagen faker\ndbutils.library.restartPython()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9687075-89ba-404d-bb2b-30d7722622aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "import uuid\nfrom datetime import datetime\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import StructType, StructField, StringType, TimestampType, DoubleType, IntegerType\nfrom pyspark.sql.functions import *\nfrom pyspark.sql.streaming import StreamingQuery\nimport dbldatagen as dg\n\n# Use existing Spark session in Databricks\nspark = SparkSession.getActiveSession()\n\nprint(f\"‚úÖ Spark version: {spark.version}\")\nprint(f\"üì¶ dbldatagen imported successfully\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5317e823-7b83-4c46-8b05-1df6e1b06045",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Simple configuration\n",
    "table_name = f\"soni.default.iot_variant_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "checkpoint_path = f\"/Volumes/soni/default/checkpoints/iot_{uuid.uuid4()}\"\n",
    "\n",
    "# Create table\n",
    "spark.sql(f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    sensor_id STRING,\n",
    "    location STRING,\n",
    "    temperature DOUBLE,\n",
    "    humidity INTEGER,\n",
    "    sensor_metadata VARIANT,\n",
    "    reading_timestamp TIMESTAMP\n",
    ") USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "print(f\"‚úÖ Table created: {table_name}\")\n",
    "print(f\"üìç Checkpoint: {checkpoint_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "930f4c3d-e8eb-4963-b067-eec8bfdc65ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": "# Create realistic IoT streaming data with dbldatagen\nprint(\"üîß Creating realistic IoT streaming data with dbldatagen...\")\n\n# Define IoT sensor schema\niot_schema = StructType([\n    StructField(\"sensor_id\", StringType(), False),\n    StructField(\"location\", StringType(), False),\n    StructField(\"temperature\", DoubleType(), False),\n    StructField(\"humidity\", IntegerType(), False),\n    StructField(\"battery_level\", IntegerType(), False),\n    StructField(\"signal_strength\", IntegerType(), False),\n    StructField(\"status\", StringType(), False),\n    StructField(\"firmware_version\", StringType(), False)\n])\n\n# Create dbldatagen specification\ndataspec = (\n    dg.DataGenerator(spark, name=\"iot_sensors\", partitions=8)\n    .withSchema(iot_schema)\n    .withColumnSpec(\"sensor_id\", minValue=1, maxValue=100, prefix=\"SENSOR_\", random=True)\n    .withColumnSpec(\"location\", values=[\"Building_A\", \"Building_B\", \"Building_C\", \"Warehouse\", \"DataCenter\"], \n                   weights=[0.25, 0.25, 0.25, 0.15, 0.1], random=True)\n    .withColumnSpec(\"temperature\", minValue=-10.0, maxValue=50.0, random=True)\n    .withColumnSpec(\"humidity\", minValue=30, maxValue=90, random=True)\n    .withColumnSpec(\"battery_level\", minValue=1, maxValue=100, random=True)\n    .withColumnSpec(\"signal_strength\", minValue=-100, maxValue=-20, random=True)\n    .withColumnSpec(\"status\", values=[\"OK\", \"SENSOR_FAIL\", \"BATTERY_LOW\", \"COMM_LOSS\"],\n                   weights=[0.8, 0.05, 0.1, 0.05], random=True)\n    .withColumnSpec(\"firmware_version\", values=[\"v1.0\", \"v2.0\", \"v2.1\"], \n                   weights=[0.2, 0.3, 0.5], random=True)\n)\n\n# Build streaming DataFrame with VARIANT metadata\nstreaming_df = (\n    dataspec.build(\n        withStreaming=True,\n        options={\n            'rowsPerSecond': 1000,\n            'numPartitions': 8\n        }\n    )\n    .withColumn(\"reading_timestamp\", current_timestamp())\n    \n    # Create complex VARIANT metadata from the generated columns\n    .withColumn(\"sensor_metadata\", \n        parse_json(to_json(struct(\n            col(\"battery_level\").alias(\"battery_level\"),\n            col(\"signal_strength\").alias(\"signal_strength\"),\n            col(\"status\").alias(\"status\"),\n            col(\"firmware_version\").alias(\"firmware_version\"),\n            current_timestamp().alias(\"last_maintenance\"),\n            \n            # Device information\n            struct(\n                lit(\"Acme Corp\").alias(\"manufacturer\"),\n                lit(\"TempSense Pro\").alias(\"model\"),\n                lit(\"2023\").alias(\"year\"),\n                concat(lit(\"TS-\"), col(\"sensor_id\")).alias(\"part_number\")\n            ).alias(\"device_info\"),\n            \n            # Network connectivity  \n            struct(\n                lit(\"WiFi\").alias(\"connection_type\"),\n                (col(\"sensor_id\").cast(\"int\") % 10 + 1).alias(\"network_id\"),\n                concat(lit(\"192.168.1.\"), (col(\"sensor_id\").cast(\"int\") % 254 + 1).cast(\"string\")).alias(\"ip_address\")\n            ).alias(\"network\"),\n            \n            # Environmental conditions\n            struct(\n                col(\"temperature\").alias(\"ambient_temp\"),\n                col(\"humidity\").alias(\"ambient_humidity\"),\n                (rand() * 200 + 800).alias(\"pressure_hpa\")\n            ).alias(\"environment\")\n        )))\n    )\n    \n    # Keep only the final columns we want\n    .select(\"sensor_id\", \"location\", \"temperature\", \"humidity\", \"sensor_metadata\", \"reading_timestamp\")\n)\n\nprint(\"‚úÖ Realistic IoT streaming DataFrame created with dbldatagen\")\nprint(\"üìä VARIANT metadata includes: battery, signal, status, device_info, network, environment\")\nprint(\"üéØ Data generation: 1000 rows/second with realistic distributions\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11e3398b-6dda-4128-b233-313fab99dead",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Start streaming with trigger(once=True) for testing\n",
    "query = (\n",
    "    streaming_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", checkpoint_path)\n",
    "    .trigger(once=True)\n",
    "    .toTable(table_name)\n",
    ")\n",
    "\n",
    "query.awaitTermination()\n",
    "print(\"‚úÖ Initial data loaded\")\n",
    "\n",
    "# Start continuous streaming\n",
    "streaming_query = (\n",
    "    streaming_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .option(\"checkpointLocation\", f\"{checkpoint_path}_continuous\")\n",
    "    .trigger(processingTime=\"10 seconds\")\n",
    "    .toTable(table_name)\n",
    ")\n",
    "\n",
    "print(\"üöÄ Streaming started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6bcd8a0-254b-42de-8d8e-f883cb428ade",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Test VARIANT column parsing\n",
    "import time\n",
    "time.sleep(30)  # Let streaming run\n",
    "\n",
    "# Stop streaming for tests\n",
    "if streaming_query.isActive:\n",
    "    streaming_query.stop()\n",
    "\n",
    "# Test 1: Basic VARIANT extraction\n",
    "spark.sql(f\"\"\"\n",
    "SELECT \n",
    "    sensor_id,\n",
    "    sensor_metadata:battery_level::INT as battery,\n",
    "    sensor_metadata:status::STRING as status\n",
    "FROM {table_name} LIMIT 3\n",
    "\"\"\").show()\n",
    "\n",
    "# Test 2: Nested VARIANT access\n",
    "spark.sql(f\"\"\"\n",
    "SELECT \n",
    "    sensor_id,\n",
    "    sensor_metadata:device_info.model::STRING as model,\n",
    "    sensor_metadata:device_info.version::STRING as version\n",
    "FROM {table_name} LIMIT 3\n",
    "\"\"\").show()\n",
    "\n",
    "print(\"‚úÖ VARIANT tests completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "543b6c3c-7c49-4ac7-93ed-0faa75a32662",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Summary\n",
    "row_count = spark.sql(f\"SELECT COUNT(*) as count FROM {table_name}\").collect()[0].count\n",
    "print(f\"üìä Final table contains {row_count:,} rows\")\n",
    "print(f\"‚úÖ VARIANT streaming demo completed\")\n",
    "print(f\"üéØ Table: {table_name}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "variant_iot_sensor_data_demo",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}